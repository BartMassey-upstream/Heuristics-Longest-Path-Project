\documentclass[twocolumn,showpacs,%
  nofootinbib,aps,superscriptaddress,%
  eqsecnum,prd,notitlepage,showkeys,11pt]{article}

\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{dcolumn}
\usepackage[hidelinks,colorlinks=true,linkcolor=blue,citecolor=blue]{hyperref}
\usepackage{titlesec}
\usepackage{minted}
\usepackage{authblk}
\usepackage[legalpaper, margin=1in]{geometry}
\frenchspacing
\setlength{\pdfpagewidth}{8.5in}
\setlength{\pdfpageheight}{11in}
\setcounter{secnumdepth}{0}

\begin{document}

\title{Heuristics in the Longest Simple Path Problem}
\author[1]{Justin J. Xie}
\author[2]{Bart Massey}
\author[2]{Cassaundra Smith}
\affil[1]{Institute for Computing in Research}
\affil[2]{Portland State University}
\date{}


\twocolumn[\begin{@twocolumnfalse}
\maketitle
\begin{abstract}
Finding the longest simple path (LSP) is a proven NP-Hard graph theory problem. While the longest path of specific groups of graphs have been shown to have polynomial solutions, the LSP problem on any arbitrary graph remains trapped in exponential behavior. The goal of this research was to explore the effectiveness of various heuristics and their potential for further use finding the longest simple path. In our exploration, we implemented heuristics inspired the well-known greedy algorithm. Other heuristics utilized the features of the graphs and their vertices to assist in finding longest simple paths. Along with creating the heuristics, we also benchmarked the performance of the heuristics on accuracy, error, and speed. With an accuracy ranging from about 80\% to 99\% on graphs with 9 vertices, the heuristics provided a considerable speed improvement to the naive, brute-force solution. In the graphs we tested, all heuristics exhibited similar behaviors where sparse graphs proved to be far more challenging to find longest simple paths in comparison to trees or dense graphs. This confirms that sparse graphs continue provide challenges for heuristics and approximation algorithms to solve. \newline
\end{abstract}
\end{@twocolumnfalse}]  

\section{\centering Introduction}

The longest simple path problem is a longstanding problem within the field of theoretical graph theory. Much work has been done on variations of this problem. Solutions to the longest paths in directed, acyclic graphs and trees are the most commonly referenced and utilized solutions. In our research, we set out to explore the longest simple path problem in undirected, unweighted, and connected graphs. As of the writing of this paper, there is no existing solution or computer capable of finding the desired solution to any arbitrary graph in polynomial time. As such, heuristics are an alternative to naive, exponential, and brute-force solutions. In comparison, brute-force methods yield guaranteed longest simple paths, while heuristics yield more inaccurate, but more efficient solutions the same problem. In our research, we applied this principle to explore what types of heuristics could function as reasonable replacements to the current naive solution.

Our main contribution is the high-level heuristics and principles we explored in two large areas. One group implemented a variation of the classic Greedy solution. Another group involved cutting the graphs into tree, in order to implement Dijkstra's algorithm for longest paths in tree. These heuristics utilized the graphs "peripheral" and "central" vertex and total graph features to determine which edges to cut.

We also introduce five heuristics that fall into one of the two categories mentioned above. We experimented with the implementation of these varied heuristics and obtained benchmark results that allow comparison to past and future exploration of the LSP problem. The data we gathered on these heuristics allowed us to gain insight on where the difficulty of finding the longest path originates from. We found that each heuristic had its own points of failure. The greedy algorithm failed to break ties and the graph pruning heuristic may not be cutting the most optimal edges. These issues can be further explored and possible remedies can be found for a more efficient and accurate heuristics. 

We found that when compared to past proposed greedy heuristics, our greedy heuristic showed similar behaviors when the number of edges in a graph was increased. It performed adequately in trees and denser graphs, where many solutions were available, but struggled with certain sparse graphs that only contained one or two possible longest simple paths. The graph pruning heuristics also showed promise for future use. On their own, they struggled to consistently cut the graph into a tree containing the longest simple path. 

Our research has shown that heuristics, although far more faster, than brute-force algorithms, often fail to account for the bigger picture. In our exploration of the LSP problem, in both the greedy and graph pruning/periphery heuristics, the heuristics that only registered and factored in data local to their ``current" position in the graph, requiring less calculations, making them faster. Longest simple paths, however, often require a view of the graph in its entirety in order to find the exact solution. This is why the heuristics that factor in all of the graph or make an extra calculation when deciding on its next vertex are the ones that outperformed in the accuracy category when compared to similar heuristics.

This is also the reason for the heuristics' improved ability to find longest paths on dense graphs in comparison to sparse graphs. Dense graphs give heuristics far more options for possible longest simple paths. As a result, even when the heuristics do not factor the entirety of the graph, the path they follow is more likely to be the LSP. In sparse graphs, there are often only one or two longest simple paths, where a single wrong turn in a heuristic's path will lead to an incorrect LSP. As has been confirmed by several other papers and their heuristics, the sparse graphs continue to be the more challenging aspect of implementing heuristics into the longest simple path problem.

\section{\centering The Longest Simple Path Problem}
\subsection{Background}
The longest simple path (LSP) in graph is the longest possible path that originates at any vertex and traverses the graph without repeating vertices. The problem is an NP-Hard problem, meaning that there has yet to be a general solution capable of finding the LSP on any arbitrary graph in polynomial time. The problem that arises from the NP characteristics is that with as the number of vertices and the size of the graph increases, the algorithm that guarantees an accurate solution hits an ``exponential wall" where even the fastest and most optimized hardware struggle to efficiently identify the longest simple path in an efficient manner.

Certain graphs are solvable in polynomial time. One type of graph is the directed acyclic graph. The longest path of these graphs can be found in linear time through inverting each edge's weight and solving it as a shortest path problem using topological sort. Similarly trees---undirected, acyclic graphs---are also solvable in linear time through Dijkstra's Dangle Algorithm by finding two ``extremes" of a tree, found through two breadth first searches, whose distance equals the longest path in that tree \cite{club2002computing}. However, as a general problem over any arbitrary graph, there is no solution to finding the longest simple path in polynomial time. As a result, heuristics are required to obtain more efficient results with a trade-off of accuracy.

\subsection{Related Work} 
The longest simple path problem is a constantly revisited problem. While no general solution has been found, continual research into the problem have proven new groups and subgroups of graphs to have polynomial time solutions or even linear time solutions like directed, acyclic graphs, or trees \cite{club2002computing}. Block graphs and weighted trees have been shown to have linear time solutions; Cacti graphs in $\mathcal{O}(n^2)$ time \cite{uehara2004efficient, uehara2007computing}. Bipartite Permutation graphs, too, have an $\mathcal{O}(n)$ solution \cite{uehara2007linear}. Interval graphs are solvable in $\mathcal{O}(n^4)$ time \cite{ioannidou2009longest,  giannopoulou2015polynomial}, Circular-Arc graphs in $\mathcal{O}(n^4)$ time \cite{mertzios2011computing}, Co-Comparability graphs in $\mathcal{O}(n^4)$ time \cite{mertzios2012simple}, and Ptolemaic graphs in $\mathcal{O}(n^5)$ time \cite{takahara2008longest}.

Each group of graphs has its own set of properties that allow them to have polynomial time solutions. But, due to their specialization, these algorithmic, polynomial time solution are unable to be generalized to the broader longest simple path problem on any graph. At the time of this writing, there is no derived solution and the LSP problem remains an NP-Hard problem. 

Like the small subcategories of graphs, the general LSP problem has been intensively studied by many. One notable approach is through dynamic programming approach and graph partitioning \cite{balyo2017optimal}, and later parallelization \cite{fieger2019finding}. Others have attempted to find the LSP through Constraint Programming, creating an exact algorithm and a local-search tabu search algorithm, but only finding success in niche groups of graphs \cite{pham2012solving}.

Another approach has been through approximations and heuristics. Approximation algorithms aim to estimate the longest path in a graph through faster, more efficient methods. This method has been applied to specific graph groups without polynomial time solutions, like a grid graphs \cite{zhang2011approximating}, approximated in $\mathcal{O}{n^2}$, or have been used generalizing the approximation algorithm to all graphs. Examples of approximation algorithms include genetic algorithms \cite{mathew2012genetic, portugal2010study, scholvin1999approximating}, a color-coding \cite{alon1995color} inspired approximation \cite{scutella2003approximation}, a simulated annealing algorithm \cite{scholvin1999approximating}, and a tabu-search algorithm \cite{scholvin1999approximating}.

Two of the most similar approaches to the heuristics we implemented during our exploration were a graph pruning heuristic and a greedy variation heuristic. A graph pruning heuristic was ysed on grid graphs before A* and Depth-First Branch-and-Bound complete search algorithms were used to find the LSP \cite{cohen2020solving}. A greedy variation heuristic called the \emph{k}-step Greedy Lookahead employed a method of finding partial paths by looking \emph{k} vertices ahead \cite{scholvin1999approximating}.

\section{\centering Implementing Heuristics}
As the Longest Simple Path Problem for any arbitrary graph has yet to have a polynomial solution, we attempted to find efficient ways of obtaining accurate or very close approximations to the correct answer longest simple paths, which led to our implementations of various heuristics. These heuristics employed past techniques, such as the greedy or pruning algorithms, but utilized different graph characteristics. In the process of applying and testing our heuristics, we confirmed properties of the LSP problem introduced by previous works. We also discovered results to utilizing certain graph characteristics that could be helpful for future work.

\subsection{Experimental Setup}

\subsubsection{Experimental Details}
In order to implement the heuristics, we utilized the Python programming language (version 3.10.4) and its igraph package. The igraph package contains an extensive array of functions and variable types fit for quick and efficient manipulation as well as useful graph visualization tools. We utilized igraph's ability to quickly add and remove edges and vertices, as well as its functions for plotting graphs and returning important graph characteristics such number of edges, vertices, or a vertex's neighbors. The package also included functions such as get\_simple\_paths or shortest\_paths that made the translation of heuristics from idea to code a straightforward process.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{examplegraph.png}
    \caption{Example Graph, Drawn by Python-igraph}
    \label{fig:ExampleGraph}
\end{figure}

The graphs that we chose to work with were the dots and lines graphs such as the graph in Figure 1. Working with graphs that were visualized this way allowed there to be both different implementations of past heuristics like the greedy heuristic and new characteristics of graphs to be revealed.

\subsubsection{Approach}

The first step to implementing heuristics was the proof of concept. By looking at characteristics of a graph, we were able to deduce the ones that may be of use in a heuristic. Characteristics such as vertex neighbor count, diameter of the graph, and vertex centrality were all examples of graph characteristics that were involved in one or more heuristics. We often used graph features for inspiration when pondering possible heuristics.

When heuristic ideas revealed themselves to be feasible and capable of attaining accurate longest simple paths, a general or multiple versions pseudo code was written to be used in the second step: Python implementation. This was where the ideas were implemented into heuristics compatible with Python-igraph for testing. 

\subsection{Random Graph Generation}
The random graphs for visualization and benchmarking were created through a randomization process called Tree-Base-Graph-Gen. This algorithm, given a \emph{n} vertices and \emph{m} edges, creates a random, undirected, connected graph by creating a tree with all \emph{n} vertices and \(n-1\) edges. The remaining \(m - (n - 1)\) required edges are then added randomly throughout the graph.

This random graph generation, however, is not truly random. Due to the way that the algorithm chooses ``random" target edges during the base-tree creation phase, certain graph shapes are more likely to be built than others. 

\subsection{The Heuristics}

\begin{figure*}
    \centering
    \includegraphics[width=\linewidth]{GraphTVPGradientsExamples.jpg}
    \caption{Example Graphs With Gradient Representation of Total Vertex Periphery}
    \label{fig:GraphTVPGradient}
\end{figure*}

\subsubsection{The Greedy Solution}
The first group of heuristics that were explored were ones based on the classic greedy algorithm. As these algorithms depend on making the ``best" decision at their current location in the problem, or in this case, the graph. In order to utilize this principle, there needed to be a graph characteristic that was identifiable and able to be recalculated on a local scale. This led us to the graph characteristic of vertex neighbor counts. A vertex neighbor count is the number of vertices adjacent to the vertex whose neighbor count is being calculated. This was a feature of the graph that could be recomputed every step. 

The greedy heuristic utilizing the graph's vertex neighbor count feature, or the Greedy Neighbor heuristic, found the longest simple path in a graph by starting at each vertex. It would then traverse the graph by choosing adjacent vertices with the least available neighbors until there were no options left. Each step in the traversal required a recalculation of the available vertices along with their neighbor count. Each starting node would eventually end up with a greedy traversal of the graph, which was then used to calculate the greedy path from each vertex. Finally, the longest greedy path was output as the heuristics solution to the LSP problem in the given graph.

This heuristic was based on the options for the next vertex in traversing the graph. The heuristic would prioritize visiting vertices with fewer neighbors and thus a lower number of ``options" by which it could be reached. Consequentially, vertices with more neighbors were visited later, as there were more ``options" to get to them. The problem with this heuristic was that it was often in a position where two or more vertices adjacent to the current vertex had the same number of available neighbors, putting the heuristic at a crossroads of tie breaking. In our first iteration of the Greedy Neighbor heuristic, the vertex with a lower ID was chosen. While this sometimes was inconsequential, because in many cases both paths led to longest paths being found, there were also graphs where choosing the lower node ID led to a shorter path length than the desired LSP. This behavior was most noticeable in larger and sparse graphs with seven or more vertices. There needed to be a tiebreaker that could pick the correct choice instead of letting chance decide. 

The second version of the Greedy Neighbor heuristic involved a Depth-First-Search (DFS) that acted as the tiebreaker when more than one adjacent vertex had the most neighbors. This DFS was a specialized version that traversed the remaining available vertices in the graph. It prioritized visiting vertices with lower IDs (instead of randomly deciding the next vertex). For each of the tied adjacent vertices, it created a tree graph with the root being the starting DFS vertex. For each vertex that had tied with having the most neighbors, we executed the specialized DFS to create post-DFS trees. The internal path length is the sum the depth (distance from root) of all nodes. The internal path length (ipl) of each post-DFS tree was calculated and the one with the highest was chose as the next vertex to visit in the greedy traversal. 

\subsubsection{Graph Centrality, Periphery, and Pruning}
The second group of heuristics based on the centrality of the vertices. The definition of three key terms representing graph and vertex centrality are as follows: 

\begin{enumerate}
    \item \textbf{Vertex Periphery}: For any vertex \emph{A}, the vertex periphery (VP) is the longest shortest path from \emph{A} to any other vertex. The lower the vertex periphery of \emph{A}, the more central \emph{A} is.
    \item \textbf{Total Vertex Periphery}:  For any vertex \emph{A}, the total vertex periphery (TVP) is the sum of all shortest paths from \emph{A} to every other vertex. The lower the total vertex periphery of \emph{A}, the more central \emph{A} is.
    \item \textbf{Graph Periphery}: For any graph \emph{G}, the graph periphery (GP) is the sum of all total vertex periphery in \emph{G}.
\end{enumerate}

All graph centrality heuristics were based on the idea that given a graph \emph{G} with \emph{n} vertices and \emph{m} edges, if you cut specific \(m - (n - 1)\) edges, the graph will then be pruned into a tree, \emph{T}, whose longest path corresponds to the longest path in. The longest path of \emph{T} could then be found in linear time with Dijkstra's Dangle algorithm \cite{club2002computing}.

The first graph centrality heuristic was one the made use of the total vertex periphery values. Named the Prune Central Edges heuristic, it relied on the assumption that the edges connecting vertices with lower TVP (meaning that they were more central edges) were unnecessary in the LSP of the graph. However, that proved to be an incorrect assumption because during testing, it was found that in certain instances, the edge connecting vertices with the lowest TVP, was utilized in the longest simple path.

The second graph centrality heuristic also made use of the total vertex periphery values. The Stretch Lowest TVP, this heuristic worked by choosing a vertex \emph{V} with the lowest TVP that had available edges that could be removed without disconnecting the graph. Next, the heuristic would find and cut the edge connecting to \emph{V} that, when removed, would increase the TVP of \emph{V} the most. This heuristic operated under the idea that the optimal tree---containing the longest path---would have the highest possible graph periphery. By removing edges from the vertices with low TVP, the heuristic would be increasing the TVP of the vertices and stretching the GP of the graph.

Through our testing, it was found that in certain graphs, the edges that would increase the TVP of a vertex were edges that were a crucial part of the graph's LSP. As a result, the principle that this exact heuristic followed was not the correct way to go about cutting the graph into a tree.

The third graph centrality heuristic made use of the graph periphery (GP). The Stretch Total Graph heuristic operated by finding looping through all removable edges (ones that did not create discontinuities in the graph) and finding the one that brought about the largest increase in the GP when removed. Similar to the Strech Lowest TVP heuristic, the Stretch Total Graph heuristic also worked to remove edges the lowered the graph periphery and to stretch the graph out to its widest possible tree. 

Similar to the Stretch Lowest TVP heuristic, it was revealed that there were graphs that did not apply to the principle used in the Stretch Total Graph heuristic. There were certain graphs where the edge that increased the GP the most were part of the longest simple path. Other graphs had edges that increased the GP the same. With no tiebreaker method, the edge with lower vertex IDs would be chosen to be removed. As such, there were graphs where necessary edges were removed because of ties between edges.

\section{\centering Results}
\subsection{Benchmarking Methods}
For the testing and benchmarking of our heuristics, we created three tests to measure crucial areas of the Longest Simple Path Problem: accuracy, error, and runtime. For consistency, the graphs used throughout all tests were the same graphs. The tests were as follows:

\begin{enumerate}
    \item \textbf{Accuracy:} The percentage of graphs that a given heuristic gets the exact longest simple paths for.
    \item \textbf{Error:} The average difference between the actual longest simple path and longest simple path found by a given heuristic.
    \item \textbf{Runtime:} The time of average execution time of a given heuristic over a group of graphs.
\end{enumerate}

\subsection{Testing Results}
The accuracy benchmark confirmed the findings of several past experiments. All heuristics were seen to have a ``canyon" behavior. At any vertex count, as the edge count increases, the accuracy of the heuristics decrease to a lower bound, then increases after hitting the lower bound. In other words, the LSP of tree graphs, and dense graphs were a accurately found by the heuristics, while the sparse and non-tree graphs were the difficult graphs to find a correct LSP for. This confirms the claims of other studies that have said the sparse graphs to be the real challenge of the LSP problem. 

In addition, the accuracy tests also reveal that both variants of the greedy algorithm, with and without the depth-first-search tiebreaker, were both guaranteed to get the correct LSP in dense graphs, which also confirms previous findings. For graph pruning graphs, the accuracy shown was worse than the greedy heuristics, signalling that, as stand-alone heuristics, they are not as effective as greedy heuristics. However, it is possible that implementing them in tandem with something like A* or local search could produce desirable results.

The runtime tests we administered showed that in comparison to the naive, brute-force solution, all heuristic runtimes grew at a slower pace. The brute-force solution has a clear exponential growth in runtime as the number of edges increases, while the heuristics have runtimes that increase more gradually. The one exception to this behavior was the heuristic that stretched the graph periphery. Because of its need to loop through all edges each time, in sparse graphs, it has a slower runtime than the brute-force algorithm. Furthermore, as the number of vertices increases, its runtime also increases by a larger degree than other heuristics. Despite its relative inefficiencies, the stretching graph periphery heuristic is still more efficient than the naive solution.

\section{\centering Conclusions}
In this paper, we covered the difficulties of the longest simple path problems as well as the directions in which we explored possible implementations of heuristics for more efficient solutions or approximations to finding the LSP. Through our experimentation, we confirmed past findings about the greedy heuristics abilities to solve the LSP problem on dense graphs and difficulties that sparse graphs provide to the problem. We also discussed the reasoning behind the various graph pruning heuristics. Although, they may not be as accurate as the greedy heuristics, they showed potential to be combined with heuristic searches such as A* or local search for possible heuristics in future work.

\section*{Acknowledgements}

\bibliographystyle{plain}
\bibliography{References.bib}

\end{document}