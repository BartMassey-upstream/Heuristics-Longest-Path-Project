7/14 Update:

Today I worked on 2 things:

    1. Coding an algorithm utilizing heuristics that I thought I could solve the problem
    2. Researchng more about heuristics and graph theory in general

For the coding side of things. I had a couple of ideas for the code I had done yesterday. 
I wrote a cleaner and commented version of that idea. However, it turns out that the code is as accurate as I had hoped. 
From my debugging and testing, I have deduced that the problem is my algorithm takes the vertex with a lower id when two vertices have the same "potential" destination points. 
If I were to try and fix this, it would very likely become a recursive function with what I have in mind. I'll have to more testing on that.

For research, I search online about the longest path of an undirected, unweighted graph and found very little as it is an NP-hard problem. 
However, there were people talking about longest path on unweighted trees, which I remember Bart talking about in the first meeting we had. 
I also saw people were discussing both DFS and BFS so i wonder if those can somehow be used on undirected, unweighted graphs in general.


7/15 Update:
Today I worked on 3 things:

    1. Cleaning code and git repo as per Bart and Cassaundra's suggestions
    2. Wrote and ran a benchmarking program for testing runtimes of my brute-force longest path algorithm and my antigreedy heuristic
    3. Read the paper explaining Dijkstra's formula and attempted to implement it into Python

For cleaning my code and repo, I basically went through a checklist of my notes from the 7/14 weekly meeting:
    - Added basic overview and name to the top of all files
    - Changed all file names to lowercase
    - Change file names to better describe their function
    - Streamlined areas of code that were in need of some revisions

For benchmarking, I did as Bart suggested and ran 4 functions, two for the brute-force algorithm, and two for my heuristic. 
I tested both as functions of n (nodes) and m (edges) and found that many of the functions had exponential trendlines.
I ran the 4 functions in 2 seperate runs to get more results, but overall found that the graphs in run 1 matched those in run 2
Also I found that my heuristic was far more efficient than the brute-force algorithm, allowing me to run much larger node and edge ranges.
Note: When testing the runtimes as a function of nodes, Run1 and Run2 were both done with the 3/4 the maximum amount of possible edges.
The graphs that I got from benchmarking are in the folder labeled 'longest_path_benchmarking_data'

For Dijstrka's algorithm, I read the paper. Much of it was quite confusing, but I felt like I understood enough to implement it.
I understood that there were 2 breadth first searches performed to find two "extremes" in a tree in order to find the longest path.
I programmed that in python and uploaded it to my repo under the name 'implementing_dijkstras'


7/18 Update:
Today I worked mainly worked on some ideas that I had.

Using Dijkstra's algorithm that I programmed last Friday, I tried to use it on graphs other than trees and went on a deep dive 
to see if I could convert non-tree graphs into tree-graphs using Prim's or Kruksal's spanning tree algorithms.

I also looked into depth first search to see how it might help me in my heuristics.

Currently, for both of these items, I still have some ideas I want to test tomorrow, but today they did not yield too much.


7/19 Update:
Today I worked on 2 things:

    1. Finish testing my ideas for topological sort, DFS, and spanning tree related code
    2. Worked on the new algorithm that Bart gave me

For testing my own ideas, I thought that I was onto something with DFS and spanning trees by cutting unwanted edges into a tree so I could use Dijkstra's tree algorithm.
This did not yield any success, however, it does seem like I was on the right track.

For the new algorithm that Bart gave me, I worked on internalizing what it was doing and drawing a few proof-of-concept graphs to experiment with it.
It turns out that the direction I was going with DFS and spanning trees was the right direction with the wrong approach.
I began to do some concept testing with code in a new file titled "graph_pruning.py" in my github project repo, and will contineu to work on it tomorrow


7/20 Update
Today I worked on:

    1. The Periphery Pruning Heuristic

Today, I was able to create a program that find the total periphery at each vertex and colors it a color on a gradient, relative to the other vertex's total periphery. 

I also was able to create a heuristic that removes edges that connect the vertices with the lowest periphery values. 
The heuristic was somewhat accurate when the raph was small (around 7 or 8 vertices), but got more inaccurate as the number of vertices increased.
As it turns out, after writing my pseudocode and discussing with Bart, I realized that I had implemented a different version than we had initially discussed.

Tomorrow, I hope to implement another version of the heuristic that removes edges that connect the vertices with the highest periphery values.
I also hope to implement the heuristic that maximizes the overall periphery of a graph. I'll see how that goes tomorrow.


7/21 Update:
Today I worked on:

    1. More Periphery Cutting/Pruning heuristics

Today I was able to write very similar heuristics. One heuristic finds the edge in the graph that, when removed, maximizes the total periphery of the entire graph.
The other heuristic was one that found the vertex with the lowest total periphery and found the edge that would maximize the total periphery at that point, if an edge was possible to remove.

Both these heuristics were pretty accurate for smaller less complex graphs, but when scaled up were very inaccurate. 
I noticed that all 3 of the periphery heuristics so far are slower and on average, more inaccurate compared to my previous greedy-based heuristic.
From a quick benchmark that I did, the periphery heuristic that combs the entire graph is the slowest out of all. 

There are a couple of other variations that I might try to implement tomorrow. It most depends on what is discussed in the meeting tonight.


7/22 Update:
Today I worked on:

    1. The Benchmarking Suite
    2. Outlining my paper

Today I worked on creating a more organize and easier to use benchmark suite. I was able to successfully create most of it. 
Currently it tests for accuracy and error and has the ability to plot those for all heuristics. Later, I plan on creating runtime versions, but that is not as important right now.
I ran some test benchmarking for both changes in edges and changes in vertices. 
For changes in edges I noticed the accuracy of most heuristics, especially the periphery ones, was significantly worse in the beginning-middle area. 
The accuracy was a canyon-like shape.

For my paper, I opened a new Overleaf file and found an online sample format as my temporary format. I outlined my paper into sections.
I also wrote a very short introduction that could be expanded upon, or could be revised into an abstract.


7/25 Update:
Today I worked on:

    1. Improving the greedy heuristic
    2. Improving benchmark suite

Today involved a lot of troubleshooting and bug fixing for both tasks that i was working on.

For the greedy heuristic, in my small graph visualization/testing, I thought that I could apply DFS to vertices with equal neighbors to act as a tiebreaker.
However, that proved more difficult to implement than I thought it would. Eventually I got it to work. It is in 'dfs_greedy_heuristic'
When testing it on the same set of graphs as the old greedy heuristic, it performed marginally worse. 

For the benchmark suite, I spent time troubleshooting files and directory names. 
I created functions for reading and writing graphs into lgl files. Located in 'graph_to_file.py'
I added the file reading capability into the complete accuracy benchmark and was testing it. Still a work in progress

Tomorrow, I need to finish rounding out the benchmark suite with files and command line arguments.
I also need to update to README to be more detailed.
If I have time, I will try to figure out why my heuristic did not improve after I added DFS.
I also need to continue my report/paper.


7/26 Update:
Today I worked on:

    1. Finished benchmarks suite (mostly)
    2. Writing the abstract and introduction to my paper

Today I finished most of the benchmark suite that allows me to take in files. It took some time to figure out the os and directory packages for Python.
However, once I got that finished, I realized that I would have to add extra functions for more testing capability. 
I added a function that executes all graph sets over a group of heuristics. I also added a function that executes a single graph set any number of heuristics.
I also discovered that the function that plots accuracy as a function of edges won't work very well with static graph sets that have been created already.
I did not modify that function as a result.

I also started on writing more of my paper. I was able to write an abstract and expand that out to an introduction, modeling some published papers on arxiv.
The introduction may still be a bit short. I can add some more detailed discoveries once I use my benchmark functions.


7/27 Update:
Today I worked on:

    1. Organizing the git repo
    2. Running the graph-fail benchmark on all heuristics
    3. Writing the background for the longest path section of my paper

